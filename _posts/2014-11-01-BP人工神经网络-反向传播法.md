---
layout: post
title:  "BP人工神经网络-反向传播法"
date:   2014-11-01 16:06 +0800
category: 机器学习
tags:   神经网络
from:   http://www.cnblogs.com/qiusuo/p/4067285.html
---
<p><img src="http://images.cnitblog.com/blog/662741/201411/011541355814234.png" alt="" /></p>
<p>0 网络计算结果</p>
<p>　　B(m)<span style="color: #000000;">=f( <span style="color: #000000;">&sum;</span><sub>n</sub>( W(n,m)*X(n) )&nbsp;+ &Theta;(m) )　　%中间层的输出</span></p>
<p><span style="color: #000000;">　　Y(k)=f( <span style="color: #000000;">&sum;</span><sub>m</sub>( V(m,k)*B(m) )&nbsp;+ ф(k) )　　%输出层的输出</span></p>
<p>1 计算误差值</p>
<p>　　E(k)=Y'(k)-Y(K)　　　　%Y'表示样本真实的输出值</p>
<p>2 计算校正误差</p>
<p>　　dV(k)=E(K) * Y(k) * ( 1-Y(k) )* [学习率]</p>
<p>　　dW(m)=<span style="color: #000000;">&sum;</span><sub>k</sub>( dV(k) * V(m,k) ) * B(m) * ( 1-B(m) )&nbsp;* [学习率]</p>
<p>3 误差校正</p>
<p>　　V(m,k)=V(m,k) + dV(k) * B(m)</p>
<p>　　W(n,m)=W(n,m) + dW(m) * X(n)</p>
<p>　　ф(k)=ф(k) + dV(k) * [学习率]</p>
<p>　　&Theta;(m)=&Theta;(m) + &nbsp;dW(m)* [学习率]</p>
<p>4 matlab代码</p>
<p>　　</p>
<div class="cnblogs_Highlighter">
<pre class="brush:python;gutter:true;">%% 构建人工神经网络
% input_train,网络的输入，1500个样本，每个样本24个因子
% output_train,网络的输出，与输入样本数相同为1500个，每个输出有4个因子

in_num=24;%输入的因子数
mid_num=25;%中间层的个数
out_num=4;%输出的因子数

W1=rands(mid_num,in_num);%每个输入对中间层的权重
TD1=rands(1,mid_num);%中间层的阈值
W2=rands(out_num,mid_num);%中间层对输出的权重
TD2=rands(1,out_num);%输出的阈值

%学习率
xite=0.1;%权重的学习率
alfa=0.01;%阈值的学习率

loop_num=100;%训练迭代的次数

%% 网络训练
for loop=1:loop_num
    for index=1:1500
        input=input_train(index,:);
        % 计算中间层输出
        mid_out=input*W1'+TD1;
        mid_out=1./(1+exp(-mid_out));
        % 计算网络的输出
        output=mid_out*W2'+TD2;
        output=1./(1+exp(-output));
        % 计算权重的下降梯度
        E= output_train(index,:) - output;
        dW2 = E .* output .* (1 - output) * xite;
        dW1 = dW2 * W2 .* mid_out .* (1-mid_out) * xite;
        % 更新权重
        W2=W2 + diag( dW2) * repmat(mid_out,out_num,1);
        W1=W1 + diag(dW1) * repmat(input,mid_num,1);
        % 更新阈值
        TD2=TD2+dW2*xite;
        TD1=TD1+dW1*xite;
    end
end
</pre>
</div>
<p>&nbsp;代码与示例数据</p>
<p><a href="http://download.csdn.net/detail/long7782/8112627">http://download.csdn.net/detail/long7782/8112627</a></p>
